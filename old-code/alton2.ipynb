{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url_alton = \"https://www.foodnetwork.com/profiles/talent/alton-brown/recipes\" + \"/recentlyaired-/p/{}\", 54+1\n",
    "base_url_show = \"https://www.foodnetwork.com/shows/good-eats/recipes\" + \"/recentlyaired-/p/{}\", 46+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def template_to_urls(template, max):\n",
    "    return [template.format(i) for i in range(1, max+1)]\n",
    "    \n",
    "def get_soup(url):\n",
    "    response = requests.get(url)\n",
    "    if not response.ok:\n",
    "        raise ValueError(\"{} could not be retrieved.\".format(url))\n",
    "    return BeautifulSoup(response.text, \"lxml\")\n",
    "\n",
    "def soup_to_reviews(soup):\n",
    "    recipe_reviews = {\n",
    "        \"https:\" + item.a.get(\"href\") :\n",
    "        (\n",
    "            item.find(attrs={'class': \"gig-rating-stars\"}).get('title') if item.find(attrs={'class': \"gig-rating-stars\"}) else None, \n",
    "            item.find(attrs={'class': \"gig-rating-ratingsum\"}).text if item.find(attrs={'class': \"gig-rating-ratingsum\"}) else None,\n",
    "        )\n",
    "        for item in soup.find(attrs={'class': \"l-List\"}).find_all(attrs={'class': \"m-MediaBlock__m-TextWrap\"})\n",
    "    }\n",
    "    \n",
    "    return recipe_reviews\n",
    "\n",
    "def soup_to_recipes(soup):\n",
    "    recipe_urls = [\n",
    "        \"https:\" + item.a.get(\"href\") \n",
    "        for item in soup.find(attrs={'class': \"l-List\"}).find_all(attrs={'class': \"m-MediaBlock__m-TextWrap\"})\n",
    "    ]\n",
    "    return recipe_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recipe_urls1 = {}\n",
    "for url in tqdm(template_to_urls(*base_url_alton)):\n",
    "    new_urls = soup_to_reviews(get_soup(url))\n",
    "    if len(new_urls) != 15:\n",
    "        print(len(new_urls), url)\n",
    "    recipe_urls1.update(**new_urls)\n",
    "\n",
    "print(len(recipe_urls1.keys()), '>', len(set(recipe_urls1.keys())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recipe_urls2 = {}\n",
    "for url in tqdm(template_to_urls(*base_url_show)):\n",
    "    new_urls = soup_to_reviews(get_soup(url))\n",
    "    if len(new_urls) != 15:\n",
    "        print(len(new_urls), url)\n",
    "    recipe_urls2.update(**new_urls)\n",
    "\n",
    "print(len(recipe_urls2.keys()), '>', len(set(recipe_urls2.keys())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reviews = pd.DataFrame()\n",
    "for url, v in recipe_urls1.items():\n",
    "    name = url.split('/')[-1]\n",
    "    reviews = int(v[1].split(' ')[0]) if v[1] else None\n",
    "    stars = float(v[0].split(' ')[0]) if v[0] else None\n",
    "    assert name not in df_reviews.index\n",
    "    df_reviews = df_reviews.append(pd.Series(data={'url': url, 'stars': stars, 'reviews': reviews}, name=name))\n",
    "for url, v in recipe_urls2.items():\n",
    "    name = url.split('/')[-1]\n",
    "    reviews = int(v[1].split(' ')[0]) if v[1] else None\n",
    "    stars = float(v[0].split(' ')[0]) if v[0] else None\n",
    "    if name in df_reviews.index:\n",
    "        assert df_reviews.loc[name,'url'] == url\n",
    "        if stars: assert df_reviews.loc[name,'stars'] == stars\n",
    "        if reviews: assert df_reviews.loc[name,'reviews'] == reviews\n",
    "        continue\n",
    "    df_reviews = df_reviews.append(pd.Series(data={'url': url, 'stars': stars, 'reviews': reviews}, name=name))\n",
    "df_reviews.sort_values(['stars', 'reviews'], ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recipe_urls = set(recipe_urls1).union(recipe_urls2)\n",
    "print(len(recipe_urls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Path('recipe_urls.txt').write_text('\\n'.join(recipe_urls))\n",
    "assert recipe_urls == set(Path('recipe_urls.txt').read_text().split('\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = recipe_urls\n",
    "b = set(df_reviews.url.unique())\n",
    "len(a), len(b), len(a-b), len(b-a), len(a.union(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(df_reviews.url.unique()) - recipe_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recipe_urls - set(df_reviews.url.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get recipes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recipe_urls = set(Path('recipe_urls.txt').read_text().split('\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_urls(urls):\n",
    "    skipped = []\n",
    "    error = []\n",
    "    downloaded = []\n",
    "    for url in tqdm(urls):\n",
    "        filename = Path('/'.join(url.split('//')[1].split('/')[1:]) + '.html')\n",
    "        if filename.exists() and filename.read_text(encoding='utf8').strip():\n",
    "            skipped += [url]\n",
    "            continue\n",
    "        filename.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        response = requests.get(url)\n",
    "        if not response.ok:\n",
    "            error += [url]\n",
    "            continue\n",
    "        text = response.text\n",
    "        \n",
    "        filename.write_text(text, encoding='utf8')\n",
    "        downloaded += [url]\n",
    "    print(f'skipped: {len(skipped)}  error: {len(error)}  downloaded: {len(downloaded)}  TOTAL: {len(skipped + error + downloaded)}')\n",
    "\n",
    "\n",
    "download_urls(recipe_urls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# process recipes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recipe_files = sorted(Path('recipes').glob('**/*.html'))\n",
    "recipe_files[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_to_soup(filename):\n",
    "    return BeautifulSoup(Path(filename).read_text(encoding='utf8'), 'lxml')\n",
    "\n",
    "\n",
    "def soup_to_data(soup):\n",
    "    ret = {}\n",
    "    recipe = soup.find(attrs={'class': \"o-Recipe\"})\n",
    "    if not recipe:\n",
    "        return None\n",
    "    # summary\n",
    "    recipe_summary = recipe.find(attrs={'class': \"m-RecipeSummary\"})\n",
    "    ret['Title'] = recipe_summary.find(attrs={'class': \"o-AssetTitle__a-HeadlineText\"}).text\n",
    "    ret['Author'] = recipe_summary.find(attrs={'class': \"o-Attribution__m-TextWrap\"}).a.text\n",
    "    ret['Rating_stars'] = recipe_summary.find(attrs={'class': \"gig-rating-stars \"})\n",
    "    ret['Rating_stars'] = ret['Rating_stars'] and ret['Rating_stars'].get('title')\n",
    "    ret['Rating_num'] = recipe_summary.find(attrs={'class': \"gig-rating-ratingsum \"})\n",
    "    ret['Rating_num'] = ret['Rating_num'] and ret['Rating_num'].text\n",
    "    recipe_info = recipe_summary.find(attrs={'class': \"o-RecipeInfo\"})\n",
    "    for ul in recipe_info.find_all('ul'):\n",
    "        for li in ul.find_all('li'):\n",
    "            span1, *span2 = li.find_all('span')\n",
    "            k = span1.text.strip(':').strip()\n",
    "            v = '\\n'.join(s.text.strip() for s in span2)\n",
    "            assert k not in ret\n",
    "            ret[k] = v\n",
    "    # footer\n",
    "    recipe_footer = recipe.find(attrs={'class': \"recipe-body-footer\"})\n",
    "    recipe_sources = recipe_footer.find(attrs={'class': \"o-VideoPromo\"})\n",
    "    if recipe_sources:\n",
    "        for recipe_source in recipe_sources.find_all(attrs={'class': \"m-MediaBlock__a-Source\"}):\n",
    "            span1, *span2 = recipe_source.find_all('span')\n",
    "            k = span1.text.strip(':').strip()\n",
    "            if k == \"Episodes\":\n",
    "                k = k[:-1]\n",
    "            v = '\\n'.join(s.text.strip() for s in span2)\n",
    "            assert k not in ret\n",
    "            ret[k] = v\n",
    "    recipe_tags = recipe_footer.find(attrs={'class': \"o-Capsule__m-TagList m-TagList\"})\n",
    "    if recipe_tags:\n",
    "        ret['Categories'] = ';'.join([tag.text for tag in recipe_tags.find_all('a')])\n",
    "    # body / ingredients\n",
    "    ingredients = recipe.find(attrs={'class': \"o-Ingredients__m-Body\"})\n",
    "    if ingredients:\n",
    "        ingredient_title = \"Ingredients\"\n",
    "        section_count = 0\n",
    "        ret[ingredient_title] = []\n",
    "        for ingredient in ingredients.find_all(['p', 'h6']):\n",
    "            if ingredient.name == 'p':\n",
    "                ret[ingredient_title] += [ingredient.text]\n",
    "            else:\n",
    "                section = ingredient.text.strip().strip(':')\n",
    "                section_count += 1\n",
    "                ingredient_title = f\"Ingredients.{section_count}.{section}\"\n",
    "                assert ingredient_title not in ret\n",
    "                ret[ingredient_title] = []\n",
    "    # body / method\n",
    "    method = recipe.find(attrs={'class': \"o-Method__m-Body\"})\n",
    "    ret['Directions'] = [li.text.strip() for li in method.find_all('li')]\n",
    "    return ret\n",
    "\n",
    "# soup = file_to_soup(recipe_files[22])\n",
    "# soup_to_data(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {}\n",
    "for filename in tqdm(recipe_files):\n",
    "    k = filename.name.split('.')[0].split('-')[-1]\n",
    "    while k in data:\n",
    "        k += '_'\n",
    "    data[k] = soup_to_data(file_to_soup(filename))\n",
    "    if data[k] is None:\n",
    "        print(f\"{k} couldn't parse as recipe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Path('recipe_data.json').open(mode='w') as f:\n",
    "    json.dump(data, f)\n",
    "with Path('recipe_data.json').open() as f:\n",
    "    assert data == json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Path('recipe_data.json').open() as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "for name, d in tqdm(data.items(), leave=False):\n",
    "    if d:\n",
    "        d2 = d.copy()\n",
    "        if \"Ingredients\" in d2:\n",
    "            ing_len = 0\n",
    "            for k in list(d2):\n",
    "                if k.startswith(\"Ingredients\"):\n",
    "                    ing_len += len(d2.pop(k))\n",
    "            d2[\"n_Ingredients\"] = ing_len\n",
    "        if \"Directions\" in d2:\n",
    "            d2[\"n_Directions\"] = len(d2.pop(\"Directions\"))\n",
    "        df = df.append(pd.Series(d2, name=name.split('-')[-1]))\n",
    "    else:\n",
    "        df = df.append(pd.Series(name=name.split('-')[-1]))\n",
    "new_col_order = [k for k in d2.keys() if k in df.columns] + [c for c in df.columns if c not in (d2.keys())]\n",
    "df = df[new_col_order]\n",
    "\n",
    "df.index.name = \"foodnetwork_id\"\n",
    "df['Author'] = df['Author'].str.replace(\"Recipe courtesy of \", \"\").astype('category')\n",
    "df['Rating_stars'] = df['Rating_stars'].replace('pending rating', pd.np.NaN).astype(float)\n",
    "df['Rating_num'] = df['Rating_num'].astype(float)  # Int\n",
    "df['Level'] = df['Level'].astype('category')\n",
    "df['Show'] = df['Show'].astype('category')\n",
    "df['n_Ingredients'] = df['n_Ingredients'].astype(float)  # Int\n",
    "df['n_Directions'] = df['n_Directions'].astype(float)  # Int\n",
    "df['Nutrition Info'] = df['Nutrition Info'].str.strip().replace('', pd.np.NaN)\n",
    "total = df.Total.str.split('\\n', expand=True)\n",
    "df['Total'] = total[0]\n",
    "df['note_Total'] = total[1].dropna()\n",
    "for c in 'Total Cook Inactive Prep Active'.split():\n",
    "    df[f't_{c}'] = pd.to_timedelta(df.pop(c))\n",
    "df = df.dropna(axis=1, how='all')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle('recipe_df.pickle')\n",
    "assert pd.read_pickle('recipe_df.pickle').equals(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# use DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pint\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('recipe_df.pickle')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_categories = []\n",
    "df_categories = pd.Series(sum((cat for cat in df.Categories.str.split(';',).dropna().values if cat), []))\n",
    "df_categories.value_counts().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(df_categories).value_counts().head(25).iloc[::-1].plot.barh(figsize=(6, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.Categories.str.contains(\"Crowd\") == True][['Title', 'Episode', 'Yield', 't_Total', ]].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_dict = {'g': ['ounce', 'oz', 'pound']}\n",
    "def convert_unit(ingredient, convert_dict):\n",
    "    s = ingredient\n",
    "    ureg = pint.UnitRegistry()\n",
    "    ureg.default_format = '.1f'\n",
    "    try:\n",
    "        for dst_unit, src_units in convert_dict.items():\n",
    "            for unit in src_units:\n",
    "                if unit in s:\n",
    "                    pos = s.find(' ', s.find(unit))\n",
    "                    before, after = s[:pos], s[pos:]\n",
    "                    return str(ureg.Quantity(before).to(dst_unit)) + after\n",
    "    except pint.DimensionalityError:\n",
    "        return s\n",
    "    return s\n",
    "\n",
    "def convert_units(ingredients, convert_dict):\n",
    "    return [\n",
    "        convert_unit(ingredient, convert_dict)\n",
    "        for ingredient in ingredients\n",
    "    ]\n",
    "\n",
    "for k in list(data.keys())[:10]:\n",
    "    pprint(convert_units(data[k]['Ingredients'], c_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_recipe(recipe):\n",
    "    for k, v in recipe.items():\n",
    "        if v is None:\n",
    "            continue\n",
    "        if k == \"Categories\":\n",
    "            v = v.split(';')\n",
    "        elif k == \"Ingredients\":\n",
    "            v = convert_units(v, c_dict)\n",
    "        if isinstance(v, list):\n",
    "            print()\n",
    "            print(k)\n",
    "            print(\"=\" * len(k))\n",
    "            pprint(v)\n",
    "        else:\n",
    "            print(f'{k+\":\":16} {v}')\n",
    "print_recipe(data['1939636'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
